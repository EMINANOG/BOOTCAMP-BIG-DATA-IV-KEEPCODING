{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PrácticaDL-Regresion-02.ipynb","provenance":[{"file_id":"1FQNnrHuy-7iZ24oyiGvZOomXQCe526e7","timestamp":1580382959094}],"collapsed_sections":[],"authorship_tag":"ABX9TyOJ3gdAobGUgcmPT7jsM/ZU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QolhxNDVMx4v","colab_type":"text"},"source":["#**Regresión Keras.**\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"cddb9a3d-5e16-43c7-d44c-1ad710e78071","executionInfo":{"status":"ok","timestamp":1580683189899,"user_tz":-60,"elapsed":1399,"user":{"displayName":"E MIN","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBfimOqhMLNfQkhW92DtoyEHm90YQ8JHcfZWrSFRQ=s64","userId":"09902616180052958600"}},"id":"t4l0Zuz_lvpy","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# Primero cargamos librerías y funciones necesarias\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt # para dibujar\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split\n","\n","#Para trabajar en el colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Cargamos los ficheros de train y test generados en los colab anterior\n","airbnbMadrid_train_DF = pd.read_csv('/content/drive/My Drive/BootCamp - BigDataIV - DL/PracticaDL-Regresion/train2-reg.csv', sep=';', decimal='.') # cargamos fichero train en un dataset\n","airbnbMadrid_test_DF = pd.read_csv('/content/drive/My Drive/BootCamp - BigDataIV - DL/PracticaDL-Regresion/test2-reg.csv', sep=';', decimal='.') # cargamos fichero test en un dataset\n"],"execution_count":198,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X56VD13S2xih","colab_type":"code","colab":{}},"source":["#Eliminamos campos \n","airbnbMadrid_train_DF = airbnbMadrid_train_DF.drop(['Number of Reviews'], axis=1)\n","airbnbMadrid_test_DF = airbnbMadrid_test_DF.drop(['Number of Reviews'], axis=1)\n","airbnbMadrid_train_DF = airbnbMadrid_train_DF.drop(['Número de registros'], axis=1)\n","airbnbMadrid_test_DF = airbnbMadrid_test_DF.drop(['Número de registros'], axis=1)\n","airbnbMadrid_train_DF = airbnbMadrid_train_DF.drop(['Country_Code_mean_enc'], axis=1)\n","airbnbMadrid_test_DF = airbnbMadrid_test_DF.drop(['Country_Code_mean_enc'], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V7a_PHm5fh3d","colab_type":"code","colab":{}},"source":["X_train = airbnbMadrid_train_DF  # DF train \n","X_test = airbnbMadrid_test_DF    # DF test "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5q1LOjYS11Yd","colab_type":"code","colab":{}},"source":["from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.optimizers import Adam\n","from keras.layers.pooling import MaxPooling2D\n","from keras.utils import to_categorical\n","\n","# Centramos los datos (le restamos la media)\n","X_train_mean = np.mean(X_train, axis = 0)\n","X_train_cent = X_train - X_train_mean\n","\n","# Normalizamos\n","X_train_std = np.std(X_train, axis = 0)\n","X_train_norm = X_train_cent / X_train_std"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LKHgKyrRhZOd","colab_type":"code","colab":{}},"source":["X_test_norm = (X_test - X_train_mean) / X_train_std"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-kuIAQYZN-Sb","colab_type":"code","colab":{}},"source":["#X_test_norm.reindex(sorted(X_test.columns), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ox0fhKrslm1A","colab_type":"code","colab":{}},"source":["#Y_train = X_train.Price\n","#Y_test = X_test.Price\n","\n","Y_train = X_train_norm.Price\n","Y_test = X_test_norm.Price"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gk67NuwalgAK","colab_type":"code","colab":{}},"source":["X_test = X_test.drop(['Price'], axis=1)\n","X_train = X_train.drop(['Price'], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnBE4vK0V_7w","colab_type":"code","colab":{}},"source":["X_test_norm = X_test_norm.values\n","X_train_norm = X_train_norm.values\n","#Y_train = Y_train.values\n","#Y_test = Y_test.values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TIdYwmifsDfZ","colab_type":"code","outputId":"fda0bf7d-8e1f-47df-a4fd-3b24722a61ad","executionInfo":{"status":"ok","timestamp":1580683268693,"user_tz":-60,"elapsed":80148,"user":{"displayName":"E MIN","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBfimOqhMLNfQkhW92DtoyEHm90YQ8JHcfZWrSFRQ=s64","userId":"09902616180052958600"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras import optimizers\n","\n","model = Sequential()\n","\n","model.add(Dense(128, input_dim=36, activation=\"relu\"))\n","model.add(Dense(64, activation=\"relu\"))\n","model.add(Dense(32, activation=\"relu\"))\n","model.add(Dense(16, activation=\"relu\"))\n","model.add(Dense(8, activation=\"relu\"))\n","model.add(Dense(4, activation=\"relu\"))\n","model.add(Dense(1, activation=\"linear\"))\n","\n","# Probamos con Adam, accuracy, mean_absolute_error\n","model.compile(loss='mean_absolute_error',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","# Entrenamos el modelo\n","model.fit(X_train_norm, Y_train, batch_size=32,shuffle=True,epochs=100,\n","          validation_data=(X_test_norm, Y_test),verbose=1) \n","\n","# Evaluamos el modelo\n","scores = model.evaluate(X_test_norm, Y_test)\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"],"execution_count":207,"outputs":[{"output_type":"stream","text":["Train on 10616 samples, validate on 2655 samples\n","Epoch 1/100\n","10616/10616 [==============================] - 3s 254us/step - loss: 0.1860 - acc: 4.7099e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 2/100\n","10616/10616 [==============================] - 1s 82us/step - loss: 0.0605 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 3/100\n","10616/10616 [==============================] - 1s 85us/step - loss: 0.0438 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 4/100\n","10616/10616 [==============================] - 1s 82us/step - loss: 0.0353 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 5/100\n","10616/10616 [==============================] - 1s 83us/step - loss: 0.0317 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 6/100\n","10616/10616 [==============================] - 1s 84us/step - loss: 0.0265 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 7/100\n","10616/10616 [==============================] - 1s 84us/step - loss: 0.0267 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 8/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0243 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 9/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0250 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 10/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0226 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 11/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0226 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 12/100\n","10616/10616 [==============================] - 1s 74us/step - loss: 0.0205 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 13/100\n","10616/10616 [==============================] - 1s 74us/step - loss: 0.0181 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 14/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0185 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 15/100\n","10616/10616 [==============================] - 1s 74us/step - loss: 0.0178 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 16/100\n","10616/10616 [==============================] - 1s 75us/step - loss: 0.0172 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 17/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0166 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 18/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0148 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 19/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0161 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 20/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0162 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 21/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0155 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 22/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0150 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 23/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0144 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 24/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0146 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 25/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0137 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 26/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0141 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 27/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0124 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 28/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0124 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 29/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0118 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 30/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0125 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 31/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0118 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 32/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0115 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 33/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0120 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 34/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0116 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 35/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0101 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 36/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0108 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 37/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0117 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 38/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0119 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 39/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0101 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 40/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0110 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 41/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0101 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 42/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0112 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 43/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0095 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 44/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0097 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 45/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0103 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 46/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0102 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 47/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0093 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 48/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0098 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 49/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0091 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 50/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0096 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 51/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0089 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 52/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0097 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 53/100\n","10616/10616 [==============================] - 1s 74us/step - loss: 0.0090 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 54/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0091 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 55/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0083 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 56/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0090 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 57/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0081 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 58/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0087 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 59/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0085 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 60/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0083 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 61/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0079 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 62/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0086 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 63/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0082 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 64/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0079 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 65/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0074 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 66/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0083 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 67/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0079 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 68/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0084 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 69/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0082 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 70/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0079 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 71/100\n","10616/10616 [==============================] - 1s 79us/step - loss: 0.0078 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 72/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0078 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 73/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0071 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 74/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0075 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 75/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0071 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 76/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0070 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 77/100\n","10616/10616 [==============================] - 1s 74us/step - loss: 0.0077 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 78/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0066 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 79/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0067 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 80/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0081 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 81/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0078 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 82/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0072 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 83/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0073 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 84/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0075 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 85/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0070 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 86/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0064 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 87/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0072 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 88/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0068 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 89/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0069 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 90/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0068 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 91/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0072 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 92/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0064 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 93/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0069 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 94/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0064 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 95/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0069 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 96/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0066 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 97/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0073 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 98/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0058 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 99/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0066 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 100/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0065 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","2655/2655 [==============================] - 0s 29us/step\n","Loss: nan\n","Accuracy: 0.000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sabFnCNg7Z9I","colab_type":"text"},"source":["Este modelo da Loss : nan y Accuracy 0.000, con todas las variables normalizadas."]},{"cell_type":"code","metadata":{"id":"bLgI32Qc7Zsi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1e26f436-cf38-4f56-bfa7-a37ac09fddb2","executionInfo":{"status":"ok","timestamp":1580683340213,"user_tz":-60,"elapsed":151659,"user":{"displayName":"E MIN","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBfimOqhMLNfQkhW92DtoyEHm90YQ8JHcfZWrSFRQ=s64","userId":"09902616180052958600"}}},"source":["from keras import optimizers\n","\n","model = Sequential()\n","\n","model.add(Dense(128, input_dim=36, activation=\"relu\"))\n","model.add(Dense(64, activation=\"relu\"))\n","model.add(Dense(32, activation=\"relu\"))\n","model.add(Dense(16, activation=\"relu\"))\n","model.add(Dense(8, activation=\"relu\"))\n","model.add(Dense(4, activation=\"relu\"))\n","model.add(Dense(1, activation=\"linear\"))\n","\n","# Probamos con lr=0.001, decay=1e-6, momentum=0.9, mean_squared_error\n","sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='mean_squared_error', optimizer=sgd,metrics=['accuracy'])\n","\n","# Entrenamos el modelo\n","model.fit(X_train_norm, Y_train, batch_size=32,shuffle=True,epochs=100,\n","          validation_data=(X_test_norm, Y_test),verbose=1) \n","\n","# Evaluamos el modelo\n","scores = model.evaluate(X_test_norm, Y_test)\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"],"execution_count":208,"outputs":[{"output_type":"stream","text":["Train on 10616 samples, validate on 2655 samples\n","Epoch 1/100\n","10616/10616 [==============================] - 2s 216us/step - loss: 0.3329 - acc: 3.7679e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 2/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0477 - acc: 5.6518e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 3/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0313 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 4/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0238 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 5/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0196 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 6/100\n","10616/10616 [==============================] - 1s 61us/step - loss: 0.0168 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 7/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0146 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 8/100\n","10616/10616 [==============================] - 1s 61us/step - loss: 0.0131 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 9/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0118 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 10/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.0107 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 11/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0099 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 12/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0091 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 13/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0086 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 14/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0080 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 15/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0077 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 16/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0072 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 17/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.0068 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 18/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0065 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 19/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0063 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 20/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0060 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 21/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0058 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 22/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0056 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 23/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0053 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 24/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0051 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 25/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0050 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 26/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.0048 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 27/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.0046 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 28/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0045 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 29/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0044 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 30/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0043 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 31/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0041 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 32/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.0040 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 33/100\n","10616/10616 [==============================] - 1s 67us/step - loss: 0.0039 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 34/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0038 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 35/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0037 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 36/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0036 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 37/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0036 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 38/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0035 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 39/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0034 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 40/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0033 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 41/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.0033 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 42/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.0032 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 43/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0032 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 44/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0031 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 45/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0030 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 46/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0030 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 47/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0029 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 48/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0029 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 49/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0028 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 50/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0028 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 51/100\n","10616/10616 [==============================] - 1s 61us/step - loss: 0.0027 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 52/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0027 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 53/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0027 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 54/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0026 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 55/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0026 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 56/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0026 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 57/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0025 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 58/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0025 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 59/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.0025 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 60/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0024 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 61/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0024 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 62/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0023 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 63/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.0023 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 64/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0023 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 65/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0023 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 66/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0022 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 67/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0022 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 68/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0022 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 69/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.0022 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 70/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0021 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 71/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0021 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 72/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0021 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 73/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0021 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 74/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0020 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 75/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0020 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 76/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0020 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 77/100\n","10616/10616 [==============================] - 1s 61us/step - loss: 0.0020 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 78/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0019 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 79/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0019 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 80/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.0019 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 81/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0019 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 82/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.0019 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 83/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0019 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 84/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.0018 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 85/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.0018 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 86/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0018 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 87/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0018 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 88/100\n","10616/10616 [==============================] - 1s 74us/step - loss: 0.0018 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 89/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0018 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 90/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0017 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 91/100\n","10616/10616 [==============================] - 1s 74us/step - loss: 0.0017 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 92/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0017 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 93/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0017 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 94/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0017 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 95/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0017 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 96/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0016 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 97/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0016 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 98/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0016 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 99/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0016 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 100/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.0016 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","2655/2655 [==============================] - 0s 33us/step\n","Loss: nan\n","Accuracy: 0.000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LvrF3hNT_NUG","colab_type":"text"},"source":["De nuevo Accuracy 0.00 y loss nan "]},{"cell_type":"code","metadata":{"id":"nlwPymgM90Nk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3d5e5173-49e2-44e2-a90b-79bed5bc50b4","executionInfo":{"status":"error","timestamp":1580683378025,"user_tz":-60,"elapsed":189463,"user":{"displayName":"E MIN","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBfimOqhMLNfQkhW92DtoyEHm90YQ8JHcfZWrSFRQ=s64","userId":"09902616180052958600"}}},"source":["from keras import optimizers\n","\n","model = Sequential()\n","\n","model.add(Dense(128, input_dim=36, activation=\"relu\"))\n","model.add(Dense(64, activation=\"relu\"))\n","model.add(Dense(32, activation=\"relu\"))\n","model.add(Dense(16, activation=\"relu\"))\n","model.add(Dense(8, activation=\"relu\"))\n","model.add(Dense(4, activation=\"relu\"))\n","model.add(Dense(1, activation=\"linear\"))\n","\n","# Probamos con RMS\n","RMS = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=1e-6)\n","model.compile(loss='mean_absolute_error', optimizer=RMS,metrics=['accuracy'])\n","\n","# Entrenamos el modelo\n","model.fit(X_train_norm, Y_train, batch_size=32,shuffle=True,epochs=100,\n","          validation_data=(X_test_norm, Y_test),verbose=1) \n","\n","# Evaluamos el modelo\n","scores = model.evaluate(X_test_norm, Y_test)\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"],"execution_count":209,"outputs":[{"output_type":"stream","text":["Train on 10616 samples, validate on 2655 samples\n","Epoch 1/100\n","10616/10616 [==============================] - 3s 246us/step - loss: 0.2314 - acc: 5.6518e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 2/100\n","10616/10616 [==============================] - 1s 75us/step - loss: 0.0743 - acc: 5.6518e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 3/100\n","10616/10616 [==============================] - 1s 76us/step - loss: 0.0546 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 4/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0452 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 5/100\n","10616/10616 [==============================] - 1s 75us/step - loss: 0.0391 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 6/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0362 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 7/100\n","10616/10616 [==============================] - 1s 75us/step - loss: 0.0325 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 8/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0307 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 9/100\n","10616/10616 [==============================] - 1s 76us/step - loss: 0.0292 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 10/100\n","10616/10616 [==============================] - 1s 76us/step - loss: 0.0282 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 11/100\n","10616/10616 [==============================] - 1s 80us/step - loss: 0.0270 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 12/100\n","10616/10616 [==============================] - 1s 74us/step - loss: 0.0262 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 13/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0256 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 14/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0245 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 15/100\n","10616/10616 [==============================] - 1s 67us/step - loss: 0.0243 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 16/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0243 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 17/100\n","10616/10616 [==============================] - 1s 67us/step - loss: 0.0231 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 18/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.0229 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 19/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.0225 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 20/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0217 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 21/100\n","10616/10616 [==============================] - 1s 67us/step - loss: 0.0220 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 22/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0215 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 23/100\n","10616/10616 [==============================] - 1s 67us/step - loss: 0.0211 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 24/100\n","10616/10616 [==============================] - 1s 67us/step - loss: 0.0211 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 25/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0209 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 26/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0204 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 27/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0201 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 28/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0200 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 29/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0198 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 30/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0196 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 31/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0196 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 32/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0189 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 33/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0193 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 34/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.0190 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 35/100\n","10616/10616 [==============================] - 1s 75us/step - loss: 0.0188 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 36/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0184 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 37/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0184 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 38/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.0182 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 39/100\n","10616/10616 [==============================] - 1s 74us/step - loss: 0.0181 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 40/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0181 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 41/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.0179 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 42/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0178 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 43/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0176 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 44/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.0176 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 45/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.0175 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 46/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.0170 - acc: 6.5938e-04 - val_loss: nan - val_acc: 0.0000e+00\n","Epoch 47/100\n"," 6624/10616 [=================>............] - ETA: 0s - loss: 0.0168 - acc: 6.0386e-04"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-209-629a4119af10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Entrenamos el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m model.fit(X_train_norm, Y_train, batch_size=32,shuffle=True,epochs=100,\n\u001b[0;32m---> 19\u001b[0;31m           validation_data=(X_test_norm, Y_test),verbose=1) \n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Evaluamos el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"SROnuNRyAnxX","colab_type":"text"},"source":["\n","Acc : 0.00 y loss nan"]},{"cell_type":"code","metadata":{"id":"HRM9w4pWAmZb","colab_type":"code","colab":{}},"source":["from keras import optimizers\n","\n","model = Sequential()\n","\n","model.add(Dense(128, input_dim=36, activation=\"relu\"))\n","model.add(Dense(64, activation=\"relu\"))\n","model.add(Dense(32, activation=\"relu\"))\n","model.add(Dense(16, activation=\"relu\"))\n","model.add(Dense(8, activation=\"relu\"))\n","model.add(Dense(4, activation=\"relu\"))\n","model.add(Dense(1, activation=\"linear\"))\n","\n","# bajamos aún más el lr y cambiamos el decay \n","sgd = optimizers.SGD(lr=0.0001, decay=1e-3 / 200, momentum=0.9, nesterov=True)\n","model.compile(loss='mean_absolute_error', optimizer=sgd,metrics=['accuracy'])\n","\n","# Entrenamos el modelo\n","model.fit(X_train_norm, Y_train, batch_size=32,shuffle=True,epochs=100,\n","          validation_data=(X_test_norm, Y_test),verbose=1) \n","\n","# Evaluamos el modelo\n","scores = model.evaluate(X_test_norm, Y_test)\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mViEsyfoBKG3","colab_type":"text"},"source":["Acc : 0.00 y loss nan"]},{"cell_type":"markdown","metadata":{"id":"qGdF0WP-D4CL","colab_type":"text"},"source":["Probamos reduciendo el número de variables a 4"]},{"cell_type":"code","metadata":{"id":"r4dmRG5iBiub","colab_type":"code","colab":{}},"source":["\n","a=['Bedrooms','Beds','SquareM2','Zipcode_mean_enc']\n","X_train4 = airbnbMadrid_train_DF[a]\n","X_test4 = airbnbMadrid_test_DF[a]\n","\n","# Centramos los datos (le restamos la media)\n","X_train4_mean = np.mean(X_train4, axis = 0)\n","X_train4_cent = X_train4 - X_train4_mean\n","\n","# Normalizamos\n","X_train4_std = np.std(X_train4, axis = 0)\n","X_train4_norm = X_train4_cent / X_train4_std\n","\n","X_test4_norm = (X_test4 - X_train4_mean) / X_train4_std"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sxNmqCYDQxZ","colab_type":"code","colab":{}},"source":["X_test4_norm = X_test4_norm.values\n","X_train4_norm = X_train4_norm.values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0O-Z5X2BQtN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a486ba93-22e1-48ea-bcc8-75502bde2f59","executionInfo":{"status":"ok","timestamp":1580683667913,"user_tz":-60,"elapsed":73069,"user":{"displayName":"E MIN","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBfimOqhMLNfQkhW92DtoyEHm90YQ8JHcfZWrSFRQ=s64","userId":"09902616180052958600"}}},"source":["from keras import optimizers\n","\n","model = Sequential()\n","\n","model.add(Dense(128, input_dim=4, activation=\"relu\"))\n","model.add(Dense(64, activation=\"relu\"))\n","model.add(Dense(32, activation=\"relu\"))\n","model.add(Dense(16, activation=\"relu\"))\n","model.add(Dense(8, activation=\"relu\"))\n","model.add(Dense(4, activation=\"relu\"))\n","model.add(Dense(1, activation=\"linear\"))\n","\n","# bajamos aún más el lr y cambiamos el decay \n","sgd = optimizers.SGD(lr=0.0001, decay=1e-3 / 200, momentum=0.9, nesterov=True)\n","model.compile(loss='mean_absolute_error', optimizer=sgd,metrics=['accuracy'])\n","\n","# Entrenamos el modelo\n","model.fit(X_train4_norm, Y_train, batch_size=32,shuffle=True,epochs=100,\n","          validation_data=(X_test4_norm, Y_test),verbose=1) \n","\n","# Evaluamos el modelo\n","scores = model.evaluate(X_test4_norm, Y_test)\n","\n","print('Loss: %.3f' % scores[0])\n","print('Accuracy: %.3f' % scores[1])"],"execution_count":226,"outputs":[{"output_type":"stream","text":["Train on 10616 samples, validate on 2655 samples\n","Epoch 1/100\n","10616/10616 [==============================] - 3s 244us/step - loss: 0.5760 - acc: 6.5938e-04 - val_loss: 0.5450 - val_acc: 0.0000e+00\n","Epoch 2/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.5508 - acc: 6.5938e-04 - val_loss: 0.5274 - val_acc: 0.0000e+00\n","Epoch 3/100\n","10616/10616 [==============================] - 1s 60us/step - loss: 0.5333 - acc: 6.5938e-04 - val_loss: 0.5118 - val_acc: 0.0000e+00\n","Epoch 4/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.5179 - acc: 6.5938e-04 - val_loss: 0.4979 - val_acc: 0.0000e+00\n","Epoch 5/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.5061 - acc: 6.5938e-04 - val_loss: 0.4880 - val_acc: 0.0000e+00\n","Epoch 6/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.4980 - acc: 6.5938e-04 - val_loss: 0.4808 - val_acc: 0.0000e+00\n","Epoch 7/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4915 - acc: 6.5938e-04 - val_loss: 0.4752 - val_acc: 0.0000e+00\n","Epoch 8/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4861 - acc: 6.5938e-04 - val_loss: 0.4704 - val_acc: 0.0000e+00\n","Epoch 9/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.4814 - acc: 6.5938e-04 - val_loss: 0.4660 - val_acc: 0.0000e+00\n","Epoch 10/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4772 - acc: 6.5938e-04 - val_loss: 0.4621 - val_acc: 0.0000e+00\n","Epoch 11/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.4733 - acc: 6.5938e-04 - val_loss: 0.4585 - val_acc: 0.0000e+00\n","Epoch 12/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4697 - acc: 6.5938e-04 - val_loss: 0.4552 - val_acc: 0.0000e+00\n","Epoch 13/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4665 - acc: 6.5938e-04 - val_loss: 0.4522 - val_acc: 0.0000e+00\n","Epoch 14/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4640 - acc: 6.5938e-04 - val_loss: 0.4500 - val_acc: 0.0000e+00\n","Epoch 15/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4619 - acc: 6.5938e-04 - val_loss: 0.4478 - val_acc: 0.0000e+00\n","Epoch 16/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.4600 - acc: 6.5938e-04 - val_loss: 0.4457 - val_acc: 0.0000e+00\n","Epoch 17/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4583 - acc: 6.5938e-04 - val_loss: 0.4439 - val_acc: 0.0000e+00\n","Epoch 18/100\n","10616/10616 [==============================] - 1s 61us/step - loss: 0.4567 - acc: 6.5938e-04 - val_loss: 0.4425 - val_acc: 0.0000e+00\n","Epoch 19/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4553 - acc: 6.5938e-04 - val_loss: 0.4408 - val_acc: 0.0000e+00\n","Epoch 20/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4540 - acc: 6.5938e-04 - val_loss: 0.4395 - val_acc: 0.0000e+00\n","Epoch 21/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.4528 - acc: 6.5938e-04 - val_loss: 0.4383 - val_acc: 0.0000e+00\n","Epoch 22/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4516 - acc: 6.5938e-04 - val_loss: 0.4371 - val_acc: 0.0000e+00\n","Epoch 23/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4504 - acc: 6.5938e-04 - val_loss: 0.4359 - val_acc: 0.0000e+00\n","Epoch 24/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.4493 - acc: 6.5938e-04 - val_loss: 0.4350 - val_acc: 0.0000e+00\n","Epoch 25/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4485 - acc: 6.5938e-04 - val_loss: 0.4343 - val_acc: 0.0000e+00\n","Epoch 26/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4477 - acc: 6.5938e-04 - val_loss: 0.4333 - val_acc: 0.0000e+00\n","Epoch 27/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4468 - acc: 6.5938e-04 - val_loss: 0.4329 - val_acc: 0.0000e+00\n","Epoch 28/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4462 - acc: 6.5938e-04 - val_loss: 0.4320 - val_acc: 0.0000e+00\n","Epoch 29/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4454 - acc: 6.5938e-04 - val_loss: 0.4314 - val_acc: 0.0000e+00\n","Epoch 30/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4447 - acc: 5.6518e-04 - val_loss: 0.4315 - val_acc: 0.0000e+00\n","Epoch 31/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4440 - acc: 4.7099e-04 - val_loss: 0.4303 - val_acc: 0.0000e+00\n","Epoch 32/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4435 - acc: 4.7099e-04 - val_loss: 0.4297 - val_acc: 0.0000e+00\n","Epoch 33/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.4430 - acc: 4.7099e-04 - val_loss: 0.4292 - val_acc: 0.0000e+00\n","Epoch 34/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4424 - acc: 4.7099e-04 - val_loss: 0.4290 - val_acc: 0.0000e+00\n","Epoch 35/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.4419 - acc: 4.7099e-04 - val_loss: 0.4281 - val_acc: 0.0000e+00\n","Epoch 36/100\n","10616/10616 [==============================] - 1s 69us/step - loss: 0.4413 - acc: 4.7099e-04 - val_loss: 0.4277 - val_acc: 0.0000e+00\n","Epoch 37/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4409 - acc: 4.7099e-04 - val_loss: 0.4274 - val_acc: 0.0000e+00\n","Epoch 38/100\n","10616/10616 [==============================] - 1s 61us/step - loss: 0.4404 - acc: 4.7099e-04 - val_loss: 0.4270 - val_acc: 0.0000e+00\n","Epoch 39/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.4400 - acc: 4.7099e-04 - val_loss: 0.4268 - val_acc: 0.0000e+00\n","Epoch 40/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4395 - acc: 4.7099e-04 - val_loss: 0.4262 - val_acc: 0.0000e+00\n","Epoch 41/100\n","10616/10616 [==============================] - 1s 61us/step - loss: 0.4392 - acc: 4.7099e-04 - val_loss: 0.4260 - val_acc: 0.0000e+00\n","Epoch 42/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.4388 - acc: 4.7099e-04 - val_loss: 0.4265 - val_acc: 0.0000e+00\n","Epoch 43/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4386 - acc: 4.7099e-04 - val_loss: 0.4256 - val_acc: 0.0000e+00\n","Epoch 44/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4382 - acc: 5.6518e-04 - val_loss: 0.4255 - val_acc: 0.0000e+00\n","Epoch 45/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.4379 - acc: 4.7099e-04 - val_loss: 0.4255 - val_acc: 0.0000e+00\n","Epoch 46/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4374 - acc: 4.7099e-04 - val_loss: 0.4253 - val_acc: 0.0000e+00\n","Epoch 47/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4372 - acc: 5.6518e-04 - val_loss: 0.4251 - val_acc: 0.0000e+00\n","Epoch 48/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4368 - acc: 5.6518e-04 - val_loss: 0.4243 - val_acc: 0.0000e+00\n","Epoch 49/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4365 - acc: 5.6518e-04 - val_loss: 0.4244 - val_acc: 0.0000e+00\n","Epoch 50/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4363 - acc: 5.6518e-04 - val_loss: 0.4239 - val_acc: 0.0000e+00\n","Epoch 51/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.4359 - acc: 5.6518e-04 - val_loss: 0.4242 - val_acc: 0.0000e+00\n","Epoch 52/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.4357 - acc: 5.6518e-04 - val_loss: 0.4239 - val_acc: 0.0000e+00\n","Epoch 53/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4353 - acc: 4.7099e-04 - val_loss: 0.4232 - val_acc: 0.0000e+00\n","Epoch 54/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4351 - acc: 5.6518e-04 - val_loss: 0.4238 - val_acc: 0.0000e+00\n","Epoch 55/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4347 - acc: 5.6518e-04 - val_loss: 0.4230 - val_acc: 0.0000e+00\n","Epoch 56/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.4346 - acc: 5.6518e-04 - val_loss: 0.4229 - val_acc: 0.0000e+00\n","Epoch 57/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4343 - acc: 5.6518e-04 - val_loss: 0.4229 - val_acc: 0.0000e+00\n","Epoch 58/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4340 - acc: 5.6518e-04 - val_loss: 0.4226 - val_acc: 0.0000e+00\n","Epoch 59/100\n","10616/10616 [==============================] - 1s 61us/step - loss: 0.4338 - acc: 5.6518e-04 - val_loss: 0.4228 - val_acc: 0.0000e+00\n","Epoch 60/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4334 - acc: 5.6518e-04 - val_loss: 0.4219 - val_acc: 0.0000e+00\n","Epoch 61/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4331 - acc: 5.6518e-04 - val_loss: 0.4229 - val_acc: 0.0000e+00\n","Epoch 62/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4331 - acc: 5.6518e-04 - val_loss: 0.4223 - val_acc: 0.0000e+00\n","Epoch 63/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4328 - acc: 5.6518e-04 - val_loss: 0.4217 - val_acc: 0.0000e+00\n","Epoch 64/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.4326 - acc: 5.6518e-04 - val_loss: 0.4216 - val_acc: 0.0000e+00\n","Epoch 65/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4322 - acc: 5.6518e-04 - val_loss: 0.4223 - val_acc: 0.0000e+00\n","Epoch 66/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4322 - acc: 5.6518e-04 - val_loss: 0.4214 - val_acc: 0.0000e+00\n","Epoch 67/100\n","10616/10616 [==============================] - 1s 67us/step - loss: 0.4319 - acc: 5.6518e-04 - val_loss: 0.4212 - val_acc: 0.0000e+00\n","Epoch 68/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4317 - acc: 5.6518e-04 - val_loss: 0.4208 - val_acc: 0.0000e+00\n","Epoch 69/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4315 - acc: 5.6518e-04 - val_loss: 0.4217 - val_acc: 0.0000e+00\n","Epoch 70/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4314 - acc: 5.6518e-04 - val_loss: 0.4209 - val_acc: 0.0000e+00\n","Epoch 71/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4312 - acc: 5.6518e-04 - val_loss: 0.4215 - val_acc: 0.0000e+00\n","Epoch 72/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4309 - acc: 5.6518e-04 - val_loss: 0.4203 - val_acc: 0.0000e+00\n","Epoch 73/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4308 - acc: 5.6518e-04 - val_loss: 0.4211 - val_acc: 0.0000e+00\n","Epoch 74/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4306 - acc: 5.6518e-04 - val_loss: 0.4211 - val_acc: 0.0000e+00\n","Epoch 75/100\n","10616/10616 [==============================] - 1s 62us/step - loss: 0.4304 - acc: 5.6518e-04 - val_loss: 0.4207 - val_acc: 0.0000e+00\n","Epoch 76/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4302 - acc: 5.6518e-04 - val_loss: 0.4201 - val_acc: 0.0000e+00\n","Epoch 77/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4301 - acc: 5.6518e-04 - val_loss: 0.4203 - val_acc: 0.0000e+00\n","Epoch 78/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4298 - acc: 5.6518e-04 - val_loss: 0.4196 - val_acc: 0.0000e+00\n","Epoch 79/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.4297 - acc: 5.6518e-04 - val_loss: 0.4200 - val_acc: 0.0000e+00\n","Epoch 80/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4295 - acc: 5.6518e-04 - val_loss: 0.4199 - val_acc: 0.0000e+00\n","Epoch 81/100\n","10616/10616 [==============================] - 1s 68us/step - loss: 0.4294 - acc: 5.6518e-04 - val_loss: 0.4199 - val_acc: 0.0000e+00\n","Epoch 82/100\n","10616/10616 [==============================] - 1s 75us/step - loss: 0.4292 - acc: 5.6518e-04 - val_loss: 0.4199 - val_acc: 0.0000e+00\n","Epoch 83/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.4291 - acc: 5.6518e-04 - val_loss: 0.4201 - val_acc: 0.0000e+00\n","Epoch 84/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.4289 - acc: 5.6518e-04 - val_loss: 0.4201 - val_acc: 0.0000e+00\n","Epoch 85/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.4287 - acc: 5.6518e-04 - val_loss: 0.4196 - val_acc: 0.0000e+00\n","Epoch 86/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.4285 - acc: 5.6518e-04 - val_loss: 0.4197 - val_acc: 0.0000e+00\n","Epoch 87/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.4284 - acc: 5.6518e-04 - val_loss: 0.4200 - val_acc: 0.0000e+00\n","Epoch 88/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.4283 - acc: 5.6518e-04 - val_loss: 0.4193 - val_acc: 0.0000e+00\n","Epoch 89/100\n","10616/10616 [==============================] - 1s 73us/step - loss: 0.4281 - acc: 5.6518e-04 - val_loss: 0.4190 - val_acc: 0.0000e+00\n","Epoch 90/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.4279 - acc: 5.6518e-04 - val_loss: 0.4189 - val_acc: 0.0000e+00\n","Epoch 91/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.4279 - acc: 5.6518e-04 - val_loss: 0.4200 - val_acc: 0.0000e+00\n","Epoch 92/100\n","10616/10616 [==============================] - 1s 75us/step - loss: 0.4277 - acc: 5.6518e-04 - val_loss: 0.4190 - val_acc: 0.0000e+00\n","Epoch 93/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.4276 - acc: 5.6518e-04 - val_loss: 0.4191 - val_acc: 0.0000e+00\n","Epoch 94/100\n","10616/10616 [==============================] - 1s 72us/step - loss: 0.4274 - acc: 5.6518e-04 - val_loss: 0.4191 - val_acc: 0.0000e+00\n","Epoch 95/100\n","10616/10616 [==============================] - 1s 71us/step - loss: 0.4273 - acc: 5.6518e-04 - val_loss: 0.4186 - val_acc: 0.0000e+00\n","Epoch 96/100\n","10616/10616 [==============================] - 1s 70us/step - loss: 0.4272 - acc: 5.6518e-04 - val_loss: 0.4189 - val_acc: 0.0000e+00\n","Epoch 97/100\n","10616/10616 [==============================] - 1s 63us/step - loss: 0.4271 - acc: 5.6518e-04 - val_loss: 0.4189 - val_acc: 0.0000e+00\n","Epoch 98/100\n","10616/10616 [==============================] - 1s 66us/step - loss: 0.4269 - acc: 5.6518e-04 - val_loss: 0.4202 - val_acc: 0.0000e+00\n","Epoch 99/100\n","10616/10616 [==============================] - 1s 65us/step - loss: 0.4270 - acc: 5.6518e-04 - val_loss: 0.4193 - val_acc: 0.0000e+00\n","Epoch 100/100\n","10616/10616 [==============================] - 1s 64us/step - loss: 0.4268 - acc: 5.6518e-04 - val_loss: 0.4188 - val_acc: 0.0000e+00\n","2655/2655 [==============================] - 0s 32us/step\n","Loss: 0.419\n","Accuracy: 0.000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QN_-UbjtFciC","colab_type":"text"},"source":["Son las 23:47 y ahora es cuando me dan valores de val_loss diferentes de nan si le meto 4 variables...o bien no está bien configurado los parámetros para 36 variables, o bien hay que meter más capas."]}]}